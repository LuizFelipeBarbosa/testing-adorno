# ðŸŽµ Testing Adorno

A YouTube comment analysis project that scrapes and analyzes comments from the **Top Tracks of 2025 Global** Spotify playlist. Named after [Theodor W. Adorno](https://en.wikipedia.org/wiki/Theodor_W._Adorno), the influential philosopher and music critic, it applies his Culture Industry critique to modern audience reactions.

## Overview

This project collects YouTube comments from 31 of the most popular songs globally in 2025, enabling sentiment analysis and cultural insight extraction. The pipeline scrapes up to **310,000 comments** distributed evenly across all tracks, and includes an 8-stage Natural Language Processing (NLP) pipeline to classify comments into Adorno-grounded critique categories.

### Featured Artists

Lady Gaga & Bruno Mars Â· Billie Eilish Â· ROSÃ‰ Â· Bad Bunny Â· Kendrick Lamar & SZA Â· Sabrina Carpenter Â· The Weeknd Â· Chappell Roan Â· Arctic Monkeys Â· Coldplay Â· and more.

## Project Structure

```
testing-adorno/
â”œâ”€â”€ scraping_and_analysis/      # Scraping & Notebook Analysis
â”‚   â”œâ”€â”€ notebooks/              # Interactive experimentation & scraping
â”‚   â”œâ”€â”€ reports/                # Markdown analysis reports
â”‚   â””â”€â”€ requirements.txt        # Dependencies for scraping
â”œâ”€â”€ nlp_pipeline/               # 8-stage NLP Critique Pipeline
â”‚   â”œâ”€â”€ src/                    # Core pipeline modules
â”‚   â”œâ”€â”€ configs/                # Pipeline configuration
â”‚   â”œâ”€â”€ docs/                   # Pipeline documentation
â”‚   â”œâ”€â”€ models/                 # Saved baseline and transformer models
â”‚   â”œâ”€â”€ outputs/                # Exported predictions and analytics
â”‚   â”œâ”€â”€ tests/                  # Unit tests for the pipeline
â”‚   â”œâ”€â”€ scripts/                # Execution scripts
â”‚   â”œâ”€â”€ Makefile                # Make commands for the NLP pipeline
â”‚   â””â”€â”€ pipeline_requirements.txt # Dependencies for the pipeline
â”œâ”€â”€ data/                       # Raw and processed datasets
â”œâ”€â”€ find_youtube_urls.csv       # Input CSV with song metadata & YouTube URLs
â”œâ”€â”€ youtube_comments_merged.json# Scraped merged comments dataset (~130 MB, LFS)
â”œâ”€â”€ youtube_comments.json       # Additional scraped dataset (~126 MB, LFS)
â”œâ”€â”€ youtube_comments_old.json   # Historical comment snapshot (~107 MB, LFS)
â””â”€â”€ .gitattributes              # Git LFS tracking config
```

## Getting Started

### Prerequisites

- Python 3.8+
- [Git LFS](https://git-lfs.com/) (required for the large JSON datasets)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/LuizFelipeBarbosa/testing-adorno.git
   cd testing-adorno
   ```

2. **Pull large files:**
   ```bash
   git lfs install
   git lfs pull
   ```

3. **Install dependencies:**
   There are two levels of dependencies based on what you want to run. 
   ```bash
   # Core scraping & basic analysis
   cd scraping_and_analysis
   pip install -r requirements.txt
   cd ..
   
   # NLP critique pipeline 
   cd nlp_pipeline
   pip install -r pipeline_requirements.txt
   cd ..
   ```

### Usage

**1. Scrape comments & basic analysis:**
Navigate to `scraping_and_analysis` and open `notebooks/testing-adorno.ipynb`. This notebook uses `youtube-comment-downloader` to fetch up to 310,000 comments across the 31 videos listed in `find_youtube_urls.csv`. It also generates histograms of comment length and exports top comments.
```bash
cd scraping_and_analysis/notebooks
jupyter notebook testing-adorno.ipynb
```

**2. Run the NLP Critique Detection Pipeline:**
An 8-stage NLP pipeline evaluates comments across several Adorno-grounded classes (e.g. STANDARDIZATION, PSEUDO_INDIVIDUALIZATION, COMMODIFICATION_MARKET_LOGIC). Navigate to `nlp_pipeline` before running. You can run this end-to-end with:
```bash
cd nlp_pipeline
make test       # Run the test suite
make pipeline   # Run stages 0-5 end-to-end
```
You can also run inference on new data:
```bash
cd nlp_pipeline
python -m src.infer ../data/raw/comments.jsonl
```

## Data

The scraped comment datasets are stored as JSON Lines or JSON arrays with the following fields per comment:

| Field         | Description           |
| ------------- | --------------------- |
| `text`        | Comment text          |
| `song_title`  | Associated song title |
| `artists`     | Artist name(s)        |
| `youtube_url` | Source video URL      |
| `author`      | Comment author        |
| `votes`       | Number of likes/votes |
| `replies`     | Number of replies     |
| `time`        | Timestamp             |

> **Note:** Important JSON datasets like `youtube_comments_merged.json` are tracked with **Git LFS** due to their large size.

## Tech Stack

- **Python** â€” Core scripting language
- **pandas**, **scikit-learn**, **transformers** â€” NLP pipeline and data manipulation
- **youtube-comment-downloader** â€” Scraping logic
- **Jupyter Notebook** â€” Interactive analysis
- **matplotlib** â€” Data visualization
- **Git LFS** â€” Large file management

## License

This project is for educational and research purposes.
